{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crawling(area):\n",
    "    global count\n",
    "\n",
    "    articles = driver.find_element_by_css_selector('#section_body')\n",
    "    article_list = articles.find_elements_by_css_selector(\n",
    "        'dl > dt:nth-child(2) > a')\n",
    "    href_list = [each.get_attribute('href') for each in article_list]\n",
    "\n",
    "    title_list = [each.text for each in article_list]\n",
    "\n",
    "    for idx, article in enumerate(href_list):\n",
    "        driver.get(article)\n",
    "        article_body = driver.find_element_by_id('articleBodyContents')\n",
    "        time.sleep(0.5)\n",
    "\n",
    "        posted_time = driver.find_element_by_class_name('t11')\n",
    "        content = article_body.text\n",
    "        file_name = '{}/{}-{}.txt'.format(area, count,\n",
    "                                          posted_time.text.replace(':', '-'))\n",
    "        \n",
    "        dest_path = '{}/{}'.format('crawling',file_name)\n",
    "        with open(dest_path, 'w', encoding='UTF-8') as f:\n",
    "            title = '\\t'+title_list[idx] + '\\n\\n'\n",
    "            f.write(title + content)\n",
    "\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_page_buttons():\n",
    "    page_buttons = driver.find_elements_by_class_name('_paging')\n",
    "    return [each.get_attribute('href') for each in page_buttons]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def how_much_page_to_crawl(area, page_counts=10):\n",
    "    if page_counts == 0:\n",
    "        print('Insert more than 0')\n",
    "        return\n",
    "\n",
    "    count = 0\n",
    "    \n",
    "    buttons = get_page_buttons()\n",
    "    crawling(area)\n",
    "    page_counts -= 1\n",
    "    print('\\t','remaining page = ' + str(page_counts))\n",
    "\n",
    "    idx = 0\n",
    "    while page_counts:\n",
    "        # idx 페이지로 이동\n",
    "        driver.get(buttons[idx])\n",
    "\n",
    "        # 다음 버튼이면\n",
    "        if idx == 9:\n",
    "            buttons = get_page_buttons()\n",
    "            idx = 0\n",
    "            crawling(area)\n",
    "\n",
    "        # 다음 버튼이 아니면\n",
    "        else:\n",
    "            crawling(area)\n",
    "            idx += 1\n",
    "\n",
    "        page_counts -= 1\n",
    "        print('\\t','remaining page = ' + str(page_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "politic = 'http://news.naver.com/main/main.nhn?mode=LSD&mid=shm&sid1=100'\n",
    "economy = 'http://news.naver.com/main/main.nhn?mode=LSD&mid=shm&sid1=101'\n",
    "society = 'http://news.naver.com/main/main.nhn?mode=LSD&mid=shm&sid1=102'\n",
    "culture = 'http://news.naver.com/main/main.nhn?mode=LSD&mid=shm&sid1=103'\n",
    "world = 'http://news.naver.com/main/main.nhn?mode=LSD&mid=shm&sid1=104'\n",
    "science = 'http://news.naver.com/main/main.nhn?mode=LSD&mid=shm&sid1=105'\n",
    "\n",
    "area = [(politic, '정치'), (economy, '경제'), (society, '사회')]\n",
    "\n",
    "driver = webdriver.Chrome('chromedriver.exe')\n",
    "count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "how_many_page = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정치  Crawling Started\n",
      "\t remaining page = 19\n",
      "\t remaining page = 18\n",
      "\t remaining page = 17\n",
      "\t remaining page = 16\n",
      "\t remaining page = 15\n",
      "\t remaining page = 14\n",
      "\t remaining page = 13\n",
      "\t remaining page = 12\n",
      "\t remaining page = 11\n",
      "\t remaining page = 10\n",
      "\t remaining page = 9\n",
      "\t remaining page = 8\n",
      "\t remaining page = 7\n",
      "\t remaining page = 6\n",
      "\t remaining page = 5\n",
      "\t remaining page = 4\n",
      "\t remaining page = 3\n",
      "\t remaining page = 2\n",
      "\t remaining page = 1\n",
      "\t remaining page = 0\n",
      "\t counts of crawling =  386\n",
      "경제  Crawling Started\n",
      "\t remaining page = 19\n",
      "\t remaining page = 18\n",
      "\t remaining page = 17\n",
      "\t remaining page = 16\n",
      "\t remaining page = 15\n",
      "\t remaining page = 14\n",
      "\t remaining page = 13\n",
      "\t remaining page = 12\n",
      "\t remaining page = 11\n",
      "\t remaining page = 10\n",
      "\t remaining page = 9\n",
      "\t remaining page = 8\n",
      "\t remaining page = 7\n",
      "\t remaining page = 6\n",
      "\t remaining page = 5\n",
      "\t remaining page = 4\n",
      "\t remaining page = 3\n",
      "\t remaining page = 2\n",
      "\t remaining page = 1\n",
      "\t remaining page = 0\n",
      "\t counts of crawling =  352\n",
      "사회  Crawling Started\n",
      "\t remaining page = 19\n",
      "\t remaining page = 18\n",
      "\t remaining page = 17\n",
      "\t remaining page = 16\n",
      "\t remaining page = 15\n",
      "\t remaining page = 14\n",
      "\t remaining page = 13\n",
      "\t remaining page = 12\n",
      "\t remaining page = 11\n",
      "\t remaining page = 10\n",
      "\t remaining page = 9\n",
      "\t remaining page = 8\n",
      "\t remaining page = 7\n",
      "\t remaining page = 6\n",
      "\t remaining page = 5\n",
      "\t remaining page = 4\n",
      "\t remaining page = 3\n",
      "\t remaining page = 2\n",
      "\t remaining page = 1\n",
      "\t remaining page = 0\n",
      "\t counts of crawling =  365\n"
     ]
    }
   ],
   "source": [
    "for each in area:\n",
    "    area_link = each[0]\n",
    "    area_str = each[1]\n",
    "    \n",
    "    driver.get(area_link)\n",
    "    print(area_str,' Crawling Started')\n",
    "    \n",
    "    how_much_page_to_crawl(area_str, how_many_page)\n",
    "    print('\\t','counts of crawling = ',count)\n",
    "    \n",
    "    count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
