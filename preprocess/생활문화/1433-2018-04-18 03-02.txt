	 자율형  킬러 로봇 이 민간인을 죽이면 누구에게 책임 묻나 

 동아일보 
이중원 서울시립대 교수 김종욱 동아대 교수에게 듣는  AI 윤리 

인공지능 AI 과 윤리 문제가 당면한 현실의 문제로 대두되고 있다. 최근 KAIST가 한화와 함께 국방 AI를 연구한다는 소식이 해외 학자들의 반발을 불렀다. 이 논란은  인간 존엄을 해치는 연구는 안 한다 는 해명 끝에 수그러들었다. 미국에서 우버 등의 자율주행차가 잇달아 인명사고를 일으키기도 했다.

과학철학자로 2007년 로봇윤리헌장 제정을 주도한 이중원 서울시립대 철학과 교수  AI 로봇에 쓸 수 있는 윤리 소프트웨어를 개발 중인 로봇공학자 김종욱 동아대 교수가  AI와 윤리 를 주제로 대담을 나눴다. 17일 서울 광화문 동아미디어센터에서 만난 두 교수는  AI 기술의 발전으로 생기는 윤리 문제에 대해 시민사회가 참여하는 포괄적인 거버넌스가 필요하다 고 입을 모았다.

 AI의 급속한 발전에 따른 윤리 문제는 .

 이중원 주체의 잘못된 행위에 책임을 물어야 사회가 굴러간다. 그런데 인간이 AI에 직권을 위임하고 자율성을 부여하면서 책임을 묻는 데 문제가 생기고 있다. 군인이 민간인을 죽이면 처벌하지만  자율형  킬러 로봇이 그러면 어떻게 처벌하나  아직 방책이 없다.

 김종욱 제네바협정은 자동발사 기능이 있는 무기도 최후 발포 명령은 인간이 내리도록 돼 있다. 그러나 미사일이 날아가다 통신이 끊기면 자체적으로 위치와 목표물을 찾는다. 이건 자율형 무기일까  경계가 애매하다. 유엔이 자율 살상무기를 정의하는 회의를 16일부터 열고 있다.
군대에서 수송용으로 사용할 수 있는 로봇의 모습. 자율적인 판단으로 적과 아군을 식별해 살상하는 인공지능  킬러 로봇 이 전장에 등장하면 민간인 사상자가 대규모로 발생할 수 있다는 우려가 나온다. 그럴 경우 책임은 누구에게 물어야 할까. 동아일보DB

 사람이 AI가 작동하는 방식을 완전히 인식하고 통제할 수 있다면  사람이 책임지면 되지 않나.

 김 그게 아주 어렵다. AI의 윤리 관련 원칙이 세계적으로 지난해 많이 발표됐다. 공통적인 게 투명성과 책임성이다. 심층신경망을 보자. 노드 단자  간 연결에서 경우의 수가 엄청나다. 자율주행 AI가 보행자를 인식하지 못해도 왜 문제가 생긴 건지 찾는 게 극히 어렵다는 얘기다. 투명성은 인간이 인공지능 소프트웨어의 정상 작동 여부와 학습 중인 데이터의 종류  의도를 쉽게 이해할 수 있어야 한다는 것이다. 이런 과정을 통해 이상 여부를 조기에 파악할 수 있어야 한다.

 이 기계가 자율적 사고와 판단을 했다고 하면 무슨 책임을 어떻게 물을 것인가  기업  개발자  사용자가 모두 책임을 피해가고 문제는 미해결로 남을 수 있다. 당장은 책임 소재가 명확히 가려지지 않더라도 기업  개발자  사용자 등이 비율에 따라 책임을 나누는 걸 당사자들의 동의를 바탕으로 제도화해야 한다.

 자율주행 AI가 인명사고를 피할 수 없을 때 보행자와 운전자 중 누구를 희생시켜야 하느냐의 딜레마는 해결이 가능한가.

 김 자율주행차는 교통사고를 큰 폭으로 줄일 수 있지만 사고가 일어날 위험은 받아들여야 한다. 그런 딜레마를 마주할 확률은 매우 낮다. 그런 상황에 처할 때 보행자를 살려야 한다는 옵션을 선택한 운전자 탑승자 에게는 사회적으로 보상을 하는 것도 생각해 볼 수 있다.

 AI 윤리에 당장 중요한 것은 .

 김 미국 등에서 AI는 교도소 수감자의 재범가능성을 평가하거나 교사의 수업성취도 평가  신입사원 채용 등에 활용하고 있다. AI가 특정인에 대해 어떤 정보와 판단 과정을 통해 그런 결정을 내렸는지를 당사자에게 설명할 수 있어야 한다. 로봇 간 데이터를 주고받는 경우 사용자  관리자가 데이터베이스에 접근해 로봇이 인식하거나 상호통신하는 내용을 인간의 언어나 상징  표현만으로도 이해할 수 있어야 한다. 만약 어떤 로봇이 로봇 클라우드에서 사람을 죽이는 방법에 대한 정보를 업로드하거나 검색한다면 즉시 금지와 조사가 이뤄져야 한다.

 AI 로봇도 결국 기계이고 물건일 뿐이지 않을까.

 이 AI 로봇은 인간의 삶의 질을 높이고 편익을 증대하기 위한 것이어서 결국 점점 인간의 사고방식과 행동을 닮는 방식으로 발전할 것이다. 자율성을 가질 것이다. 다양한 층위의 인격성을 규정하고 이런 존재에 하위의 인격성을 부여하는 걸 고려할 수 있다. 유럽연합은 AI 로봇을  전자적 인격체 로 규정했다. 오늘날 법인과 비슷하게 인간이 아닌 인격체 person 로 보는 것이다. 단순한 도구가 아니라 인간이 직권을 위임해 자율성을 가진 이상 AI를 포함하는 윤리 법 제도를 만들어야 한다.
